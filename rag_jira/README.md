# RAG JIRA

> Mise en place d'un RAG pour l'analyse et la r√©solution de tickets JIRA.

- [RAG JIRA](#rag-jira)
  - [‚ÑπÔ∏è √Ä propos](#‚ÑπÔ∏è-√†-propos)
    - [üß± Structure du projet](#-structure-du-projet)
  - [üõ†Ô∏è Ex√©cution en local](#Ô∏è-ex√©cution-en-local)
    - [‚úÖ Pr√©requis](#-pr√©requis)
    - [üì¶ Installation des d√©pendances](#-installation-des-d√©pendances)
  - [üöÄ M√©thodologie](#-m√©thodologie)
    - [Filtrage des tickets JIRA](#filtrage-des-tickets-jira)
      - [Type des issues](#type-des-issues)
      - [Status des issues](#status-des-issues)
      - [Resolution des issues](#resolution-des-issues)
    - [RAG](#rag)
    - [Questions pour la d√©mo](#questions-pour-la-d√©mo)
  - [üìö Liens utiles](#-liens-utiles)


## ‚ÑπÔ∏è √Ä propos

Ce projet propose une application chatbot avec RAG pour l'analyse et la r√©solution de tickets JIRA.

Ce projet est bas√© sur le jeu de donn√©es [TAWOS](https://rdr.ucl.ac.uk/articles/dataset/The_TAWOS_dataset/21308124) (**T**awosi **A**gile **W**eb-based **O**penSource) datant d'ocotbre 2020.
- Ce dataset regroupe des donn√©es provenant de 13 r√©f√©rentiels open source diff√©rents (Apache, Atlassian, MongoDB, Spring, ...).
- Tous ces r√©f√©rentiels utilisent JIRA comme plateforme de gestion des probl√®mes.
- 44 projets ont √©t√© selectionn√©s des ces r√©f√©rentiels.
- Le dataset contient au total 508 963 issues contribu√©es par 208 811 utilisateurs.

L'ensemble de donn√©es est h√©berg√© plubliquement sur GitHub sous la forme d'une base de donn√©es relationnelle.

![Schema TAWOS](./doc/img/TAWOS_schema.png)

L'objectif de ce projet est de proposer un d√©monstrateur de RAG pour l'analyse et la r√©solution de tickets JIRA sur un projet sp√©cifique.

Les issues JIRA vont servir de base de connaissance pour le LLM qui va pouvoir analyser et r√©pondre √† un probl√®me utilisateur en s'aidant de la r√©solution d'ancien tickets JIRA.

### üß± Structure du projet

```bash
rag_jira
‚îú‚îÄ doc/img
‚îú‚îÄ src
‚îÇ   ‚îú‚îÄ entrepot                     # Package contenant tous les entrepots de donn√©es / mod√®les
‚îÇ   ‚îÇ    ‚îú‚îÄ __init__.py
‚îÇ   ‚îÇ    ‚îú‚îÄ embeddings.py
‚îÇ   ‚îÇ    ‚îú‚îÄ jira_issues.py
‚îÇ   ‚îÇ    ‚îú‚îÄ llm_models.py
‚îÇ   ‚îÇ    ‚îî‚îÄ redis_schema.yaml
‚îÇ   ‚îú‚îÄ service
‚îÇ   ‚îÇ    ‚îú‚îÄ __init__.py
‚îÇ   ‚îÇ    ‚îî‚îÄ indexation.py           # Service d'indexation de la base Redis
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ app.py                       # Application streamlit
‚îÇ
‚îú‚îÄ tests
‚îÇ   ‚îî‚îÄ ..
‚îú‚îÄ xp
‚îÇ   ‚îú‚îÄ analyse.ipynb                # Analyse des tickets jira
‚îÇ   ‚îî‚îÄ script_de_test.py
.
.
.
‚îú‚îÄ pyproject.toml                   # D√©pendances du package rag_jira
‚îî‚îÄ README.md
```

## üõ†Ô∏è Ex√©cution en local

1. D√©ployer redis localement.
```console
docker run --name redis-jira -d -p 6379:6379 redis/redis-stack:latest
```

2. Installer [Redis Insight](https://redis.io/insight/) pour visualiser le contenu de la base. Et ajouter une nouvelle base de donn√©es Redis avec les informations suivantes :
   - **host**: 127.0.0.1
   - **port**: 6379

üí° Arr√™ter / R√©d√©marrer la base :
```console
docker stop redis-jira
docker start redis-jira
```

3. Installer les d√©pendances de l'application (voir [üì¶ Installation des d√©pendances](#-installation-des-d√©pendances)).

4. Avant de lancer le chatbot, faire une indexation des tickets jira.
```console
python src/service/indexation.py
```

üí° Pour vider la base, √† l'aide du CLI de Redis Insight :
```
FLUSHDB
```

5. Lancer l'application streamlit.
```console
streamlit run src/app.py
```

L'application est disponible [ici](http://localhost:8501/).

![Application ChatBot](./doc/img/application.png)

### ‚úÖ Pr√©requis

- **Langage :** Python
- **Base de donn√©es :** SQL, Redis
- **Outils :** DBeaver ou autre, Redis Insight
- **Framework :** Langchain
- **Mod√®les LLM :** Mod√®les disponibles sur [Hugging Face](https://huggingface.co/models)
- [**D√©pendances**](./pyproject.toml)

### üì¶ Installation des d√©pendances

- Cr√©er un environnement virtuel.
  ```console
  cd rag_jira
  python -m venv venv
  ```

- Activer l'environnement virtuel avec `source venv/bin/activate` pour linux ou `venv\Scripts\activate` pour windows.

- Installer les d√©pendances du package `rag_jira`.
  ```console
  pip install -e '.[dev]'
  ```

## üöÄ M√©thodologie

### Filtrage des tickets JIRA

Nous allons nous concentrer sur un projet sp√©cifique pour faire notre application de r√©solution d'issues. Les issues et les commentaires associ√©s nous servirons de base de connaissance pour notre application.

![Tables utilis√©es pour le RAG](./doc/img/analyse_TAWOS.png)

Informations sur le projet utilis√© :
- R√©f√©rentiel : MongoDB
- Projet : MongoDB Core Server
- Language de programmation : C++
- Nombre d'issues : 48 663
- Project Key : SERVER
- ID : 33
- Description : MongoDB Enterprise Server est l'√©dition commerciale de MongoDB, disponible dans le cadre de l'abonnement MongoDB Enterprise Advanced.


Pour savoir quels tickets jira vont √™tre index√©s dans notre base Redis, nous avons fait une [analyse du jeu de donn√©es TAWOS](./xp/analyse.ipynb). Les tickets jira qui serviront de base de connaissance pour notre RAG sont stock√©s dans un fichier csv.

#### Type des issues

![Types des issues](./xp/img/types_issues.png)

Les types d'issues que nous conservons sont :
- Bug
- Question

#### Status des issues

![Status des issues](./xp/img/status_issues.png)

Il n'y a que le status Closed pour les issues que nous conservons donc puisque cela signifie que les tickets ont √©t√© trait√©s et r√©solus.

#### Resolution des issues

![Resolution des issues](./xp/img/resolution_issues.png)

Les types de r√©solution que nous tra√Ætons sont :
- Fixed
- Done
- Community Answered

### RAG

![Schema du RAG](./doc/img/schema_rag.png)

### Questions pour la d√©mo
___

**Original message :** When specifying a query for the map-reduce job, it fails. Without query it works flawlessly, unfortunately without the query it runs miserably slow on our dataset.  I am simply aggregating the records based on one of the <USER> and filter them with the query based on a 2d index. It fails. Now I'm working with a workaround to filter the records in the map() function, which obviously sucks.  I have brought to you a full step-by-step reproduction guide. It seems there is no such problem on a single instance of mongodb, as well as with a smaller dataset.

**Reformulation :** Why does specifying a query for the map-reduce job fail? Without the query, it works perfectly, but it's extremely slow on our dataset. I'm simply aggregating records based on one of the and filtering them with a 2D index-based query. This fails. Currently, I'm using a workaround to filter records in the map() function, which is far from ideal. I've prepared a step-by-step guide to reproduce the issue. This problem doesn't occur on a single MongoDB instance or with smaller datasets.

**La r√©ponse doit contenir :** I was able to workaround this by using a 2dsphere rather than a 2d index.
___

**Original message :** The {{update_test_lifecycle.py}} script fetches the test history in multiple threads.  In these threads the code calls the test_failures module which uses the {{datetime.strptime()}} method.  As filed in https://bugs.python.org/issue7980, that method does not import _strptime.py in a thread safe way.  This can lead to the following error: {{AttributeError: 'module' object has no attribute '_strptime'}}.    We need to implement a workaround: either calling the {{strptime()}} method or importing the {{_strptime}} module explicitly before starting the threads.

**Reformulation :** How can we work around the thread safety issue related to using the {{datetime.strptime()}} method in the {{update_test_lifecycle.py}} script, given that this script fetches test history using multiple threads and this can lead to an {{AttributeError: 'module' object has no attribute '_strptime'}} as mentioned in https://bugs.python.org/issue7980? Should we explicitly call the {{strptime()}} method or import the {{_strptime}} module before starting the threads to avoid this error?

**La r√©ponse doit contenir :** Resolved by removing the use of strptime() from {{test_failures.py}}
___

I've created a collection with 100k entries like:  {code} { a: <int>, b: <int>, c: <int>, txt: <5k string> } {code}  And query with:  {code} > db.foo.find({a: {$lt: 32065}, b: 23}) {code}  Explain shows this:  {code} {  ""cursor"" : ""BasicCursor"",  ""nscanned"" : 100000,  ""nscannedObjects"" : 100000,  ""n"" : 211,  ""millis"" : 140,  ""nYields"" : 0,  ""nChunkSkips"" : 0,  ""isMultiKey"" : false,  ""indexOnly"" : false,  ""indexBounds"" : {     } } {code}  But system.profile shows this:  {code} {  ""ts"" : ISODate(""2011-09-20T17:25:19.664Z""),  ""op"" : ""query"",  ""ns"" : ""test.foo"",  ""query"" : {   ""query"" : {    ""a"" : {     ""$lt"" : 32065    },    ""b"" : 23   },   ""$explain"" : true  },  ""nscanned"" : 100000,  ""nreturned"" : 1,  ""responseLength"" : 297,  ""millis"" : 0,  ""client"" : ""127.0.0.1"",  ""user"" : """" } {code}  With profiling level set to 1, the output in system.profile reflects the correct millis. The profile output in 1.8.3 is correct:  {code} {         ""ts"" : ISODate(""2011-09-20T17:24:37.464Z""),         ""info"" : ""query example.bigdocs reslen:313 nscanned:100000  \\nquery: { query: { a: { $lt: 32065.0 }, b: 23.0 }, $explain: true }  nreturned:1 bytes:297"",         ""millis"" : 56 } {code}  (Note that this behavior is true with or without .explain(), I only used that to find out the actual millis to execute the query)

**Reformulation :** How can I create a collection with 100,000 entries of the type { a: <int>, b: <int>, c: <int>, txt: <5k string> }, and query this collection with db.foo.find({a: {$lt: 32065}, b: 23}) while obtaining consistent results between the query explanation (explain) and the system profiling (system.profile), given that the profiling level is set to 1?

**La r√©ponse doit contenir :** {code}
db.setProfilingLevel(2)
{code}

use:

{code}
db.runCommand({profile: 1, slowms: 0})
{code}

___

## üìö Liens utiles

- [TAWOS Dataset](https://rdr.ucl.ac.uk/articles/dataset/The_TAWOS_dataset/21308124)
- [R√©pertoire Github TAWOS](https://github.com/SOLAR-group/TAWOS)
- [A Versatile Dataset of Agile Open Source Software Projects](https://solar.cs.ucl.ac.uk/pdf/tawosi2022msr.pdf)
- [Langchain](https://python.langchain.com/v0.2/docs/introduction/)
- [Redis VectorStore](https://python.langchain.com/v0.2/docs/integrations/vectorstores/redis/)